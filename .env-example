# Example environment variables for the updated RAG backend
# Copy this file to `.env` and adjust values as needed.


# -----------------------------------------------------------------------------
# Qdrant (Vector Database)
# -----------------------------------------------------------------------------
# URL of Qdrant service (Docker Compose exposes it on localhost:6333)
QDRANT_URL=http://localhost:6333


# Qdrant collection name for document chunks
QDRANT_COLLECTION=documents

# Vector size must match your embedding model output (jina v4 -> 2048)
QDRANT_VECTOR_SIZE=2048


# -----------------------------------------------------------------------------
# Jina AI (Embeddings)
# -----------------------------------------------------------------------------
# API key for Jina embeddings.
# Required for vectorizing documents and queries via jina-embeddings-v4.
JINA_API_KEY=your_jina_api_key_here

# Model and endpoint for embeddings
JINA_EMBEDDING_MODEL=jina-embeddings-v4
JINA_EMBEDDING_ENDPOINT=https://api.jina.ai/v1/embeddings

# Task for embeddings (e.g., text-matching for RAG similarity)
JINA_EMBEDDING_TASK=text-matching

# Expected dimension of embeddings from Jina (2048 for v4)
JINA_EMBEDDING_EXPECTED_DIM=2048

# -----------------------------------------------------------------------------
# Jina AI (Reranker)
# -----------------------------------------------------------------------------
# API key for Jina reranker (same as embeddings if not separate).
# Required for reranking retrieved chunks.
JINA_RERANKER_API_KEY=your_jina_reranker_api_key_here

# Model and endpoint for reranker
JINA_RERANKER_MODEL=jina-reranker-v3-base-en

# Reranker endpoint (adjust if different from default)
JINA_RERANKER_ENDPOINT=https://api.jina.ai/v1/rerank

# Maximum number of contexts to rerank per query
JINA_RERANKER_TOP_K=5

# -----------------------------------------------------------------------------
# OpenRouter (Generative LLM for RAG and Final Answers)
# -----------------------------------------------------------------------------
# API key for OpenRouter. Required for the generative LLM (replaces extractive QA).
# Sign up / manage keys at https://openrouter.ai/
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Base URL for OpenRouter-compatible OpenAI-style endpoint
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Model used on OpenRouter for generating answers.
# Choose a strong reasoning model that supports JSON if needed, but for generation use something like:
OPENROUTER_MODEL=openrouter/polaris-alpha

# -----------------------------------------------------------------------------
# CAG (Context-Aware Gate) Configuration
# -----------------------------------------------------------------------------
# Threshold for CAG Check: Maximum similarity score between query and any chunk.
# If max score <= CAG_THRESHOLD, respond with static message (no RAG).
# Recommended range: 0.0 to 1.0 (e.g., 0.5 for moderate similarity).
CAG_THRESHOLD=0.66

# -----------------------------------------------------------------------------
# RAG Behavior / Tuning
# -----------------------------------------------------------------------------
# Max total context length (characters) in the RAG prompt before sending to LLM
MAX_CONTEXT_CHARS=4000

# Chunking parameters for document ingestion (approximate token counts)
CHUNK_SIZE_TOKENS=500
CHUNK_OVERLAP_TOKENS=50

# Number of top similar chunks initially retrieved from Qdrant for reranking
RETRIEVAL_TOP_K=10  # More than final to allow reranking

# Final number of contexts to include in the RAG prompt after reranking
RERANKED_TOP_K=5

# -----------------------------------------------------------------------------
# Static Response (for CAG failure)
# -----------------------------------------------------------------------------
# The static message returned when CAG decides RAG is unnecessary.
STATIC_RESPONSE_MESSAGE="На основе имеющейся у меня базы знаний, я не могу предоставить ответ на ваш вопрос."

# -----------------------------------------------------------------------------
# Logging / Misc (optional)
# -----------------------------------------------------------------------------
# LOG_LEVEL=INFO
